{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mLogfire\u001b[0m project URL: \u001b]8;id=384036;https://logfire.pydantic.dev/gaohe2z/hhl-openai-agents-sdk\u001b\\\u001b[4;36mhttps://logfire.pydantic.dev/gaohe2z/hhl-openai-agents-sdk\u001b[0m\u001b]8;;\u001b\\\n"
     ]
    }
   ],
   "source": [
    "from hhl_openai_agents_sdk.models import get_gemini, get_openai, get_gemini_response\n",
    "from dotenv import load_dotenv\n",
    "import nest_asyncio\n",
    "import logfire\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# make sure we can run async code in jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# instrument logfire\n",
    "logfire.configure(token=os.getenv(\"LOGFIRE_TOKEN\"))\n",
    "logfire.instrument_openai()\n",
    "\n",
    "# initialize the model\n",
    "model = get_gemini()\n",
    "# model = get_openai()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types.responses import ResponseTextDeltaEvent\n",
    "from agents import Agent, Runner\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"Joker\",\n",
    "    instructions=\"You are a helpful assistant.\",\n",
    "    model=model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:13:19.483 Chat Completion with 'gemini-2.0-flash' [LLM]\n",
      "Alright, buckle up for another round of jokes! Here we go:\n",
      "\n",
      "1.  Why don't scientists trust atoms? Because they make up everything!\n",
      "2.  What do you call a lazy kangaroo? Pouch potato!\n",
      "3.  Why did the scarecrow win an award? Because he was outstanding in his field!\n",
      "4.  What musical instrument is found in the bathroom? A tuba toothpaste.\n",
      "5.  What shirt should you wear to a tea party? A t-shirt.\n",
      "6.  Why did the bicycle fall over? Because it was two tired!\n",
      "7.  What do you call a fish with no eyes? Fsh!\n",
      "8.  Why can't Monday lift Saturday? It's a weak day.\n",
      "9.  Why did the golfer wear two pairs of pants? In case he got a hole-in-one!\n",
      "10. What do you call a sad strawberry? A blueberry.\n",
      "11. What do you call a bear with no teeth? A gummy bear!\n",
      "12. What did the math book say to the guidance counselor? \"I have so many problems.\"\n",
      "13. What's orange and sounds like a parrot? A carrot.\n",
      "14. Why did the orange stop running? Because he ran out of juice.\n",
      "15. Why did the teddy bear say no to dessert? Because she was stuffed!\n",
      "16. What do you call a fake noodle? An impasta.\n",
      "17. What does a cloud wear under his raincoat? Thunderwear!\n",
      "18. What does an Italian ghost like to eat? Spook-hetti.\n",
      "19. What did the stamp say to the envelope? Stick with me and we'll go places!\n",
      "20. How do you make an octopus laugh? With ten-tickles!\n",
      "\n",
      "I hope you enjoyed that batch of jokes! Let me know if you want some more! ðŸ˜Š\n",
      "21:13:22.092 streaming response from 'gemini-2.0-flash' took 2.28s [LLM]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result = Runner.run_streamed(agent, input=\"Please tell me 20 more jokes.\")\n",
    "async for event in result.stream_events():\n",
    "    if event.type == \"raw_response_event\" and isinstance(\n",
    "        event.data, ResponseTextDeltaEvent\n",
    "    ):\n",
    "        print(event.data.delta, end=\"\", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from agents import Agent, ItemHelpers, Runner, function_tool, ModelSettings\n",
    "\n",
    "@function_tool\n",
    "def how_many_jokes() -> int:\n",
    "    return random.randint(10, 20)\n",
    "\n",
    "\n",
    "async def main():\n",
    "    agent = Agent(\n",
    "        name=\"Joker\",\n",
    "        # instructions=\"First call the `how_many_jokes` tool, then tell that many jokes.\",\n",
    "        instructions=\"First call the `how_many_jokes` tool, it will return the count of jokes you need to tell, please use as input to decide how many jokes you tell\",\n",
    "        tools=[how_many_jokes],\n",
    "        model=model,\n",
    "        # model='gpt-4o-mini',\n",
    "        model_settings=ModelSettings(\n",
    "            temperature=0,\n",
    "            # top_p=0.9,\n",
    "            # max_tokens=100000,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    result = Runner.run_streamed(\n",
    "        agent,\n",
    "        input=\"Hello\",\n",
    "    )\n",
    "    print(\"=== Run starting ===\")\n",
    "\n",
    "    async for event in result.stream_events():\n",
    "        # We'll ignore the raw responses event deltas\n",
    "        if event.type == \"raw_response_event\":\n",
    "            # print(\"raw response event\", event)\n",
    "            continue\n",
    "        # When the agent updates, print that\n",
    "        elif event.type == \"agent_updated_stream_event\":\n",
    "            print(f\"Agent updated: {event.new_agent.name}\")\n",
    "            continue\n",
    "        # When items are generated, print them\n",
    "        elif event.type == \"run_item_stream_event\":\n",
    "            if event.item.type == \"tool_call_item\":\n",
    "                print(\"-- Tool was called\")\n",
    "            elif event.item.type == \"tool_call_output_item\":\n",
    "                print(f\"-- Tool output: {event.item.output}\")\n",
    "            elif event.item.type == \"message_output_item\":\n",
    "                print(f\"-- Message output:\\n {ItemHelpers.text_message_output(event.item)}\")\n",
    "            else:\n",
    "                pass  # Ignore other event types\n",
    "        else:\n",
    "            print(f\"Unknown event type: {event}\")\n",
    "\n",
    "    print(\"=== Run complete ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Run starting ===\n",
      "Agent updated: Joker\n",
      "21:15:36.317 Chat Completion with 'gemini-2.0-flash' [LLM]\n",
      "21:15:36.725 streaming response from 'gemini-2.0-flash' took 0.00s [LLM]\n",
      "21:15:36.733 Chat Completion with 'gemini-2.0-flash' [LLM]\n",
      "-- Tool was called\n",
      "-- Tool output: 19\n",
      "21:15:38.779 streaming response from 'gemini-2.0-flash' took 1.78s [LLM]\n",
      "-- Message output:\n",
      " I will tell you 19 jokes.\n",
      "\n",
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!\n",
      "\n",
      "Why did the scarecrow win an award?\n",
      "\n",
      "Because he was outstanding in his field!\n",
      "\n",
      "What do you call a fish with no eyes?\n",
      "\n",
      "Fsh!\n",
      "\n",
      "Why did the bicycle fall over?\n",
      "\n",
      "Because it was two tired!\n",
      "\n",
      "What do you call a lazy kangaroo?\n",
      "\n",
      "Pouch potato!\n",
      "\n",
      "Why did the golfer wear two pairs of pants?\n",
      "\n",
      "In case he got a hole-in-one!\n",
      "\n",
      "What do you call a bear with no teeth?\n",
      "\n",
      "A gummy bear!\n",
      "\n",
      "Why did the teddy bear say no to dessert?\n",
      "\n",
      "Because she was stuffed!\n",
      "\n",
      "What do you call a cheese that isnâ€™t yours?\n",
      "\n",
      "Nacho cheese!\n",
      "\n",
      "Why did the picture go to jail?\n",
      "\n",
      "Because it was framed!\n",
      "\n",
      "What do you call a sad strawberry?\n",
      "\n",
      "A blueberry!\n",
      "\n",
      "Why did the banana go to the doctor?\n",
      "\n",
      "Because it wasnâ€™t peeling well!\n",
      "\n",
      "What musical instrument is found in the bathroom?\n",
      "\n",
      "A tuba toothpaste.\n",
      "\n",
      "Why did the robber take a bath before he robbed the bank?\n",
      "\n",
      "He wanted to make a clean getaway.\n",
      "\n",
      "Why do fish live in salt water?\n",
      "\n",
      "Because pepper makes them sneeze.\n",
      "\n",
      "What shirt should you wear to a tea party?\n",
      "\n",
      "A t-shirt.\n",
      "\n",
      "What do you call a person afraid of Santa Claus?\n",
      "\n",
      "Claustrophobic.\n",
      "\n",
      "Why did the dinosaur cross the road?\n",
      "\n",
      "Because chickens hadnâ€™t been invented yet.\n",
      "\n",
      "Why canâ€™t Monday lift Saturday?\n",
      "\n",
      "Itâ€™s a weak day.\n",
      "\n",
      "=== Run complete ===\n"
     ]
    }
   ],
   "source": [
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def main():\n",
    "    agent = Agent(\n",
    "        name=\"Joker\",\n",
    "        instructions=\"First call the `how_many_jokes` tool, then tell that many jokes.\",\n",
    "        tools=[how_many_jokes],\n",
    "        model=model,\n",
    "        # model='gpt-4o-mini',\n",
    "        # model_settings=ModelSettings(\n",
    "        #     temperature=0.9,\n",
    "        #     # top_p=0.9,\n",
    "        #     # max_tokens=100000,\n",
    "        # ),\n",
    "    )\n",
    "\n",
    "    result = Runner.run_sync(\n",
    "        agent,\n",
    "        input=\"Hello\",\n",
    "    )\n",
    "    print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20:55:07.948 Chat Completion with 'gemini-2.0-flash' [LLM]\n",
      "20:55:08.469 Chat Completion with 'gemini-2.0-flash' [LLM]\n",
      "I am programmed to tell 12 jokes.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
